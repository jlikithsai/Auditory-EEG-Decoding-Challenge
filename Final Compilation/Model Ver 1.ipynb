{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2eb8f0d6-ed24-4644-a643-5311bb41e391",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# import itertools\n",
    "# import os\n",
    "# import numpy as np\n",
    "# import torch\n",
    "# import torch.nn.functional as F\n",
    "# from torch.utils.data import Dataset, DataLoader\n",
    "# import glob\n",
    "# import json\n",
    "# import logging\n",
    "# import sys\n",
    "# import torch.nn as nn\n",
    "# import torch.optim as optim\n",
    "# import random\n",
    "# def batch_equalizer_fn(args):\n",
    "#     eeg = args[0]\n",
    "# #     print(\"eegshape=\",eeg.shape)\n",
    "#     num_stimuli = len(args) - 1\n",
    "#     # repeat eeg num_stimuli times\n",
    "#     new_eeg = torch.cat([eeg] * num_stimuli, dim=0)\n",
    "#     all_features = [new_eeg]\n",
    "# #     print(\"all_features=\",all_features[0].shape)\n",
    "\n",
    "#     # create args\n",
    "#     args_to_zip = [args[i::num_stimuli] for i in range(1, num_stimuli + 1)]\n",
    "# #     print(\"args_to_zip=\",args_to_zip[0].shape,args_to_zip[1].shape)\n",
    "\n",
    "#     for stimuli_features in zip(*args_to_zip):\n",
    "# #         print(\"stimuli_features=\",stimuli_features[0].shape,stimuli_features[1].shape)\n",
    "#         for i in range(num_stimuli):\n",
    "#             shift = i\n",
    "#             shifted_tuple = tuple(stimuli_features[(j - shift) % len(stimuli_features)] for j in range(len(stimuli_features)))\n",
    "#             stimulus_rolled = torch.stack(shifted_tuple)\n",
    "# #             print(\"stimulus_rolled=\", stimulus_rolled.shape)\n",
    "#             # reshape stimulus_rolled to merge the first two dimensions\n",
    "#             stimulus_rolled = stimulus_rolled.view(-1, stimulus_rolled.size(2), stimulus_rolled.size(3))\n",
    "# #             print(\"stimulus_rolled1=\", stimulus_rolled.shape)\n",
    "\n",
    "#             all_features.append(stimulus_rolled)\n",
    "# #     print(\"all_features1=\",all_features)\n",
    "    \n",
    "#     labels_list = [torch.tensor([[1 if ii == i else 0 for ii in range(num_stimuli)]]) for i in range(num_stimuli)]\n",
    "#     labels = torch.cat([label.repeat(eeg.size(0), 1) for label in labels_list], dim=0)\n",
    "# #     print(\"labels=\",labels)\n",
    "# #     print(\"tuple(all_features)=\", tuple(all_features))\n",
    "\n",
    "#     return tuple(all_features), labels\n",
    "\n",
    "# def shuffle_fn(args, number_mismatch):\n",
    "#     # repeat the last argument number_mismatch times\n",
    "#     args = list(args)\n",
    "#     for _ in range(number_mismatch):\n",
    "#         args.append(args[-1][torch.randperm(args[-1].size(0))])\n",
    "#     return tuple(args)\n",
    "\n",
    "# # Function to create frames from a tensor\n",
    "# def frame_tensor(tensor, window_length, hop_length):\n",
    "#     num_frames = (tensor.size(0) - window_length) // hop_length + 1\n",
    "#     frames = torch.stack(\n",
    "#         [tensor[i * hop_length : i * hop_length + window_length] for i in range(num_frames)]\n",
    "#     )\n",
    "#     return frames\n",
    "\n",
    "# def process_eeg(original_tensors_list):\n",
    "#     reshaped_tensors = [tensor[i].view(320, 64) for tensor in original_tensors_list for i in range(tensor.size(0))]\n",
    "\n",
    "#     lists_of_tensors = [reshaped_tensors[i:i+8] for i in range(0, len(reshaped_tensors), 8)]\n",
    "#     lists_of_tensors = lists_of_tensors[:len(reshaped_tensors)//8]\n",
    "\n",
    "#     # Shuffle the lists\n",
    "#     random.shuffle(lists_of_tensors)\n",
    "\n",
    "#     final_tensors = []\n",
    "#     for chunk_of_lists in zip(*(iter(lists_of_tensors),) * 8):\n",
    "#         concatenated_tensors = torch.cat([torch.unsqueeze(tensor, 0) for sublist in chunk_of_lists for tensor in sublist], dim=0).view(64, 320, 64)\n",
    "#         final_tensors.append(concatenated_tensors)\n",
    "\n",
    "#     return final_tensors\n",
    "# def process_stimuli(original_tensors_list):\n",
    "#     reshaped_tensors = [tensor[i].view(320, 1) for tensor in original_tensors_list for i in range(tensor.size(0))]\n",
    "\n",
    "#     lists_of_tensors = [reshaped_tensors[i:i+8] for i in range(0, len(reshaped_tensors), 8)]\n",
    "#     lists_of_tensors = lists_of_tensors[:len(reshaped_tensors)//8]\n",
    "\n",
    "#     # Shuffle the lists\n",
    "#     random.shuffle(lists_of_tensors)\n",
    "\n",
    "#     final_tensors = []\n",
    "#     for chunk_of_lists in zip(*(iter(lists_of_tensors),) * 8):\n",
    "#         concatenated_tensors = torch.cat([torch.unsqueeze(tensor, 0) for sublist in chunk_of_lists for tensor in sublist], dim=0).view(64, 320, 1)\n",
    "#         final_tensors.append(concatenated_tensors)\n",
    "\n",
    "#     return final_tensors\n",
    "# class PyTorchDataGenerator(Dataset):\n",
    "#     def __init__(self, files, window_length):\n",
    "#         self.window_length = window_length\n",
    "#         self.files = self.group_recordings(files)\n",
    "\n",
    "#     def group_recordings(self, files):\n",
    "#         new_files = []\n",
    "#         grouped = itertools.groupby(\n",
    "#             sorted(files), lambda x: \"_-_\".join(os.path.basename(x).split(\"_-_\")[:3])\n",
    "#         )\n",
    "#         for recording_name, feature_paths in grouped:\n",
    "#             new_files += [sorted(feature_paths, key=lambda x: \"0\" if x == \"eeg\" else x)]\n",
    "# #         print(\"new_files=\", new_files)\n",
    "#         return new_files\n",
    "    \n",
    "\n",
    "#     def __len__(self):\n",
    "#         return len(self.files)\n",
    "\n",
    "#     def __getitem__(self, recording_index):\n",
    "#         data = []\n",
    "#         for feature in self.files[recording_index]:\n",
    "#             f = np.load(feature).astype(np.float32)\n",
    "# #             print(\"f_before=\", f.shape)\n",
    "#             if f.ndim == 1:\n",
    "#                 f = f[:, None]\n",
    "# #                 print(\"f_after=\", f.shape)\n",
    "#             data += [f]\n",
    "# #         print(\"data_before=\", data)\n",
    "#         data = self.prepare_data(data)\n",
    "# #         print(\"data_after=\", data)\n",
    "# #         print(\"tuple(torch.tensor(x) for x in data)=\",tuple(torch.tensor(x) for x in data))\n",
    "#         return tuple(torch.tensor(x) for x in data)\n",
    "\n",
    "#     def __call__(self):\n",
    "#         for idx in range(self.__len__()):\n",
    "#             yield self.__getitem__(idx)\n",
    "\n",
    "#             if idx == self.__len__() - 1:\n",
    "#                 self.on_epoch_end()\n",
    "\n",
    "#     def on_epoch_end(self):\n",
    "#         np.random.shuffle(self.files)\n",
    "\n",
    "#     def prepare_data(self, data):\n",
    "#         # make sure data has dimensionality of (n_samples, n_features)\n",
    "#         return data\n",
    "\n",
    "# def create_pytorch_dataset(\n",
    "#     data_generator,\n",
    "#     window_length,\n",
    "#     batch_equalizer_fn=None,\n",
    "#     frame_tensor=None,\n",
    "#     process_eeg=None,\n",
    "#     process_stimuli=None,\n",
    "#     hop_length=64,\n",
    "#     batch_size=64,\n",
    "#     number_mismatch=None,\n",
    "#     data_types=(torch.float32, torch.float32),\n",
    "#     feature_dims=(64, 1)\n",
    "# ):\n",
    "#     dataset = data_generator\n",
    "#     if frame_tensor is not None:\n",
    "#         i=0\n",
    "#         for data in dataset:\n",
    "#             dataset = [(frame_tensor(data[0], window_length, hop_length),frame_tensor(data[1], window_length, hop_length),)]\n",
    "\n",
    "\n",
    "#     if number_mismatch is not None:\n",
    "#         # map second argument to shifted version\n",
    "#         dataset = [\n",
    "#         shuffle_fn(data, number_mismatch) for data in dataset\n",
    "#     ]\n",
    "    \n",
    "#     if process_eeg is not None and process_stimuli is not None:\n",
    "#         # map second argument to shifted version\n",
    "#         dataset=[process_eeg([data[0] for data in dataset]),\n",
    "#         process_stimuli([data[1] for data in dataset]),\n",
    "#         process_stimuli([data[2] for data in dataset]),\n",
    "#         process_stimuli([data[3] for data in dataset]),\n",
    "#         process_stimuli([data[4] for data in dataset]),\n",
    "#         process_stimuli([data[5] for data in dataset])]\n",
    "#         dataset = [tuple([dataset[0][i],dataset[1][i],dataset[2][i],dataset[3][i],dataset[4][i],dataset[5][i]]) for i in range(len(dataset[0]))]\n",
    "# #         print(dataset[0][0].shape,dataset[0][1].shape,dataset[0][2].shape)\n",
    "\n",
    "#     if batch_equalizer_fn is not None:\n",
    "#         # Create the labels and make sure classes are balanced\n",
    "#         dataset = [\n",
    "#             tuple(batch_equalizer_fn(args)) for args in dataset\n",
    "#         ]\n",
    "\n",
    "#     return tuple(dataset)\n",
    "\n",
    "# window_length_s = 5\n",
    "# fs = 64\n",
    "\n",
    "# window_length = window_length_s * fs  # 5 seconds\n",
    "# # Hop length between two consecutive decision windows\n",
    "# hop_length = 64\n",
    "\n",
    "# epochs = 100\n",
    "# patience = 5\n",
    "# batch_size = 64 #fixed in the code\n",
    "# only_evaluate = True\n",
    "# number_mismatch = 4 # or 4\n",
    "\n",
    "\n",
    "\n",
    "# training_log_filename = \"training_log_{}_{}.csv\".format(number_mismatch, window_length_s)\n",
    "# data_folder = \"split_data/split_data\"\n",
    "\n",
    "# # stimulus feature which will be used for training the model. Can be either 'envelope' ( dimension 1) or 'mel' (dimension 28)\n",
    "# stimulus_features = [\"envelope\"]\n",
    "# stimulus_dimension = 1\n",
    "\n",
    "# # uncomment if you want to train with the mel spectrogram stimulus representation\n",
    "# # stimulus_features = [\"mel\"]\n",
    "# # stimulus_dimension = 10\n",
    "\n",
    "# features = [\"eeg\"] + stimulus_features\n",
    "# # print(\"features=\", features)\n",
    "# train_files = [x for x in glob.glob(os.path.join(data_folder, \"train_-_*\")) if os.path.basename(x).split(\"_-_\")[-1].split(\".\")[0] in features]\n",
    "# # Create list of numpy array files\n",
    "# train_generator = PyTorchDataGenerator(train_files, window_length)\n",
    "# import pdb\n",
    "# dataset_train = create_pytorch_dataset(train_generator, window_length, batch_equalizer_fn,frame_tensor,process_eeg,process_stimuli,\n",
    "#                                   hop_length, batch_size,\n",
    "#                                   number_mismatch=number_mismatch,\n",
    "#                                   data_types=(torch.float32, torch.float32),\n",
    "#                                   feature_dims=(64, stimulus_dimension))\n",
    "\n",
    "# val_files = [x for x in glob.glob(os.path.join(data_folder, \"val_-_*\")) if os.path.basename(x).split(\"_-_\")[-1].split(\".\")[0] in features]\n",
    "# val_generator = PyTorchDataGenerator(val_files, window_length)\n",
    "# dataset_val = create_pytorch_dataset(val_generator,  window_length, batch_equalizer_fn,frame_tensor,process_eeg,process_stimuli,\n",
    "#                                   hop_length, batch_size,\n",
    "#                                   number_mismatch=number_mismatch,\n",
    "#                                   data_types=(torch.float32, torch.float32),\n",
    "#                                   feature_dims=(64, stimulus_dimension))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d8065f1e-650c-4bc4-8ccb-8002023fff70",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import itertools\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import glob\n",
    "import json\n",
    "import logging\n",
    "import sys\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import random\n",
    "def batch_equalizer_fn(args):\n",
    "    eeg = args[0]\n",
    "#     print(\"eegshape=\",eeg.shape)\n",
    "    num_stimuli = len(args) - 1\n",
    "    # repeat eeg num_stimuli times\n",
    "    new_eeg = torch.cat([eeg] * num_stimuli, dim=0)\n",
    "    all_features = [new_eeg]\n",
    "#     print(\"all_features=\",all_features[0].shape)\n",
    "\n",
    "    # create args\n",
    "    args_to_zip = [args[i::num_stimuli] for i in range(1, num_stimuli + 1)]\n",
    "#     print(\"args_to_zip=\",args_to_zip[0].shape,args_to_zip[1].shape)\n",
    "\n",
    "    for stimuli_features in zip(*args_to_zip):\n",
    "#         print(\"stimuli_features=\",stimuli_features[0].shape,stimuli_features[1].shape)\n",
    "        for i in range(num_stimuli):\n",
    "            shift = i\n",
    "            shifted_tuple = tuple(stimuli_features[(j - shift) % len(stimuli_features)] for j in range(len(stimuli_features)))\n",
    "#             print(len(shifted_tuple))\n",
    "            stimulus_rolled = torch.stack(shifted_tuple)\n",
    "#             print(\"stimulus_rolled=\", stimulus_rolled.shape)\n",
    "            # reshape stimulus_rolled to merge the first two dimensions\n",
    "            stimulus_rolled = stimulus_rolled.view(-1, stimulus_rolled.size(2), stimulus_rolled.size(3))\n",
    "#             print(\"stimulus_rolled1=\", stimulus_rolled.shape)\n",
    "\n",
    "            all_features.append(stimulus_rolled)\n",
    "#     print(\"all_features1=\",all_features)\n",
    "    \n",
    "    labels_list = [torch.tensor([[1 if ii == i else 0 for ii in range(num_stimuli)]]) for i in range(num_stimuli)]\n",
    "    labels = torch.cat([label.repeat(eeg.size(0), 1) for label in labels_list], dim=0)\n",
    "#     print(\"labels=\",labels)\n",
    "#     print(\"tuple(all_features)=\", tuple(all_features))\n",
    "\n",
    "    return tuple(all_features), labels\n",
    "\n",
    "def shuffle_fn(args, number_mismatch):\n",
    "    # repeat the last argument number_mismatch times\n",
    "    args = list(args)\n",
    "    for _ in range(number_mismatch):\n",
    "        args.append(args[-1][torch.randperm(args[-1].size(0))])\n",
    "    return tuple(args)\n",
    "\n",
    "# Function to create frames from a tensor\n",
    "def frame_tensor(tensor, window_length, hop_length):\n",
    "    num_frames = (tensor.size(0) - window_length) // hop_length + 1\n",
    "    frames = torch.stack(\n",
    "        [tensor[i * hop_length : i * hop_length + window_length] for i in range(num_frames)]\n",
    "    )\n",
    "    return frames\n",
    "\n",
    "def process_eeg(original_tensors_list):\n",
    "    reshaped_tensors = [tensor[i].view(320, 64) for tensor in original_tensors_list for i in range(tensor.size(0))]\n",
    "\n",
    "    lists_of_tensors = [reshaped_tensors[i:i+8] for i in range(0, len(reshaped_tensors), 8)]\n",
    "    lists_of_tensors = lists_of_tensors[:len(reshaped_tensors)//8]\n",
    "\n",
    "    # Shuffle the lists\n",
    "    random.shuffle(lists_of_tensors)\n",
    "\n",
    "    final_tensors = []\n",
    "    for chunk_of_lists in zip(*(iter(lists_of_tensors),) * 8):\n",
    "        concatenated_tensors = torch.cat([torch.unsqueeze(tensor, 0) for sublist in chunk_of_lists for tensor in sublist], dim=0).view(64, 320, 64)\n",
    "        final_tensors.append(concatenated_tensors)\n",
    "\n",
    "    return final_tensors\n",
    "def process_stimuli(original_tensors_list):\n",
    "    reshaped_tensors = [tensor[i].view(320, 10) for tensor in original_tensors_list for i in range(tensor.size(0))]\n",
    "\n",
    "    lists_of_tensors = [reshaped_tensors[i:i+8] for i in range(0, len(reshaped_tensors), 8)]\n",
    "    lists_of_tensors = lists_of_tensors[:len(reshaped_tensors)//8]\n",
    "\n",
    "    # Shuffle the lists\n",
    "    random.shuffle(lists_of_tensors)\n",
    "\n",
    "    final_tensors = []\n",
    "    for chunk_of_lists in zip(*(iter(lists_of_tensors),) * 8):\n",
    "        concatenated_tensors = torch.cat([torch.unsqueeze(tensor, 0) for sublist in chunk_of_lists for tensor in sublist], dim=0).view(64, 320, 10)\n",
    "        final_tensors.append(concatenated_tensors)\n",
    "\n",
    "    return final_tensors\n",
    "class PyTorchDataGenerator(Dataset):\n",
    "    def __init__(self, files, window_length):\n",
    "        self.window_length = window_length\n",
    "        self.files = self.group_recordings(files)\n",
    "\n",
    "    def group_recordings(self, files):\n",
    "        new_files = []\n",
    "        grouped = itertools.groupby(\n",
    "            sorted(files), lambda x: \"_-_\".join(os.path.basename(x).split(\"_-_\")[:3])\n",
    "        )\n",
    "        for recording_name, feature_paths in grouped:\n",
    "            new_files += [sorted(feature_paths, key=lambda x: \"0\" if x == \"eeg\" else x)]\n",
    "#         print(\"new_files=\", new_files[0:2])\n",
    "        return new_files\n",
    "    \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.files)\n",
    "\n",
    "    def __getitem__(self, recording_index):\n",
    "        data = []\n",
    "        for feature in self.files[recording_index]:\n",
    "            f = np.load(feature).astype(np.float32)\n",
    "#             print(\"f_before=\", f.shape)\n",
    "            if f.ndim == 1:\n",
    "                f = f[:, None]\n",
    "#                 print(\"f_after=\", f.shape)\n",
    "            data += [f]\n",
    "#         print(\"data_before=\", data)\n",
    "        data = self.prepare_data(data)\n",
    "#         print(\"data_after=\", data)\n",
    "#         print(\"tuple(torch.tensor(x) for x in data)=\",tuple(torch.tensor(x) for x in data))\n",
    "        return tuple(torch.tensor(x) for x in data)\n",
    "\n",
    "    def __call__(self):\n",
    "        for idx in range(self.__len__()):\n",
    "            yield self.__getitem__(idx)\n",
    "\n",
    "            if idx == self.__len__() - 1:\n",
    "                self.on_epoch_end()\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        np.random.shuffle(self.files)\n",
    "\n",
    "    def prepare_data(self, data):\n",
    "        # make sure data has dimensionality of (n_samples, n_features)\n",
    "        return data\n",
    "\n",
    "def create_pytorch_dataset(\n",
    "    data_generator,\n",
    "    window_length,\n",
    "    batch_equalizer_fn=None,\n",
    "    frame_tensor=None,\n",
    "    process_eeg=None,\n",
    "    process_stimuli=None,\n",
    "    hop_length=64,\n",
    "    batch_size=64,\n",
    "    number_mismatch=None,\n",
    "    data_types=(torch.float32, torch.float32),\n",
    "    feature_dims=(64, 1)\n",
    "):\n",
    "    dataset = data_generator\n",
    "    if frame_tensor is not None:\n",
    "        i=0\n",
    "        for data in dataset:\n",
    "            dataset = [(frame_tensor(data[0], window_length, hop_length),frame_tensor(data[1], window_length, hop_length))]\n",
    "\n",
    "\n",
    "    if number_mismatch is not None:\n",
    "        # map second argument to shifted version\n",
    "        dataset = [\n",
    "        shuffle_fn(data, number_mismatch) for data in dataset\n",
    "    ]\n",
    "    \n",
    "    if process_eeg is not None and process_stimuli is not None:\n",
    "        # map second argument to shifted version\n",
    "        dataset=[process_eeg([data[0] for data in dataset]),\n",
    "        process_stimuli([data[1] for data in dataset])]\n",
    "        dataset = [tuple([dataset[0][i],dataset[1][i]]) for i in range(len(dataset[0]))]\n",
    "#         print(dataset[0][0].shape,dataset[0][1].shape,dataset[0][2].shape)\n",
    "\n",
    "    if batch_equalizer_fn is not None:\n",
    "        # Create the labels and make sure classes are balanced\n",
    "        dataset = [\n",
    "            tuple(batch_equalizer_fn(args)) for args in dataset\n",
    "        ]\n",
    "\n",
    "    return tuple(dataset)\n",
    "\n",
    "window_length_s = 5\n",
    "fs = 64\n",
    "\n",
    "window_length = window_length_s * fs  # 5 seconds\n",
    "# Hop length between two consecutive decision windows\n",
    "hop_length = 64\n",
    "\n",
    "epochs = 100\n",
    "patience = 5\n",
    "batch_size = 64 #fixed in the code\n",
    "only_evaluate = True\n",
    "number_mismatch = 4 # or 4\n",
    "\n",
    "\n",
    "\n",
    "training_log_filename = \"training_log_{}_{}.csv\".format(number_mismatch, window_length_s)\n",
    "data_folder = \"split_data/split_data\"\n",
    "\n",
    "# stimulus feature which will be used for training the model. Can be either 'envelope' ( dimension 1) or 'mel' (dimension 28)\n",
    "stimulus_features = [\"mel\"]\n",
    "stimulus_dimension = 10\n",
    "\n",
    "# uncomment if you want to train with the mel spectrogram stimulus representation\n",
    "# stimulus_features = [\"mel\"]\n",
    "# stimulus_dimension = 10\n",
    "\n",
    "features = [\"eeg\"] + stimulus_features\n",
    "# print(\"features=\", features)\n",
    "train_files = [x for x in glob.glob(os.path.join(data_folder, \"train_-_*\")) if os.path.basename(x).split(\"_-_\")[-1].split(\".\")[0] in features]\n",
    "# Create list of numpy array files\n",
    "train_generator = PyTorchDataGenerator(train_files, window_length)\n",
    "import pdb\n",
    "dataset_train = create_pytorch_dataset(train_generator, window_length, None,frame_tensor,process_eeg,process_stimuli,\n",
    "                                  hop_length, batch_size,\n",
    "                                  number_mismatch=None,\n",
    "                                  data_types=(torch.float32, torch.float32),\n",
    "                                  feature_dims=(64, stimulus_dimension))\n",
    "\n",
    "val_files = [x for x in glob.glob(os.path.join(data_folder, \"val_-_*\")) if os.path.basename(x).split(\"_-_\")[-1].split(\".\")[0] in features]\n",
    "val_generator = PyTorchDataGenerator(val_files, window_length)\n",
    "dataset_val = create_pytorch_dataset(val_generator,  window_length, None,frame_tensor,process_eeg,process_stimuli,\n",
    "                                  hop_length, batch_size,\n",
    "                                  number_mismatch=None,\n",
    "                                  data_types=(torch.float32, torch.float32),\n",
    "                                  feature_dims=(64, stimulus_dimension))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d5098a9a-3f5e-496d-8797-5015fa81fc5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 320, 64])\n",
      "torch.Size([64, 320, 64])\n"
     ]
    }
   ],
   "source": [
    "c = 0 \n",
    "for i in dataset_train:\n",
    "    print(i[0].shape)\n",
    "    c += 1\n",
    "    if c == 2:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1e0c7730-3978-4817-bd94-44c5a7fb27ef",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models as models\n",
    "from tqdm import tqdm \n",
    "\n",
    "class ResNet34EEG(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ResNet34EEG, self).__init__()\n",
    "        self.model = models.resnet34(pretrained=False)\n",
    "        self.model.conv1 = nn.Conv2d(64, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "class ResNet34Mel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ResNet34Mel, self).__init__()\n",
    "        self.model = models.resnet34(pretrained=False)\n",
    "        self.model.conv1 = nn.Conv2d(10, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "\n",
    "device = 'cuda'\n",
    "\n",
    "resnet_eeg = ResNet34EEG().to(device)\n",
    "resnet_mel = ResNet34Mel().to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "763d15ab-6331-433d-b5c9-56b3c68c14a8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000: 100%|████████████████████████████████████████████████████████████████████| 10/10 [00:01<00:00,  9.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000, Average Loss: 98.72620544433593\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/1000: 100%|████████████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 12.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/1000, Average Loss: 56.95190620422363\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/1000: 100%|████████████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 12.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/1000, Average Loss: 118.0544921875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/1000: 100%|████████████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 12.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/1000, Average Loss: 718.684610748291\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/1000: 100%|████████████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 12.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/1000, Average Loss: 234.31207809448242\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/1000: 100%|████████████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 11.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/1000, Average Loss: 101.77684860229492\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/1000: 100%|████████████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 11.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/1000, Average Loss: 65.59778480529785\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/1000: 100%|████████████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 12.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/1000, Average Loss: 379.46421375274656\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/1000: 100%|████████████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 12.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/1000, Average Loss: 206.14080047607422\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/1000: 100%|███████████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 12.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/1000, Average Loss: 64.87923202514648\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/1000: 100%|███████████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 12.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/1000, Average Loss: 51.59086799621582\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/1000: 100%|███████████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 12.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/1000, Average Loss: 41.13090877532959\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13/1000: 100%|███████████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 12.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/1000, Average Loss: 28.846663856506346\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14/1000: 100%|███████████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 12.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/1000, Average Loss: 22.57915668487549\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15/1000: 100%|███████████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 12.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/1000, Average Loss: 19.413301467895508\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16/1000: 100%|███████████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 11.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/1000, Average Loss: 18.07600326538086\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17/1000: 100%|███████████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 12.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/1000, Average Loss: 16.9896409034729\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18/1000: 100%|███████████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 11.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/1000, Average Loss: 16.738549327850343\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19/1000: 100%|███████████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 11.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/1000, Average Loss: 16.420489025115966\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20/1000: 100%|███████████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 11.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/1000, Average Loss: 15.954123878479004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 21/1000: 100%|███████████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 11.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/1000, Average Loss: 15.965904903411865\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 22/1000: 100%|███████████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 11.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/1000, Average Loss: 15.38379364013672\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 23/1000: 100%|███████████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 12.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/1000, Average Loss: 15.697805786132813\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 24/1000: 100%|███████████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 12.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/1000, Average Loss: 16.068480587005617\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 25/1000: 100%|███████████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 12.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/1000, Average Loss: 15.434966468811036\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 26/1000: 100%|███████████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 12.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/1000, Average Loss: 16.25449914932251\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 27/1000: 100%|███████████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 12.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/1000, Average Loss: 15.850018405914307\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 28/1000: 100%|███████████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 12.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/1000, Average Loss: 15.824216556549072\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 29/1000: 100%|███████████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 12.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/1000, Average Loss: 15.867222213745118\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 30/1000: 100%|███████████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 11.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/1000, Average Loss: 16.02628927230835\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 31/1000: 100%|███████████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 12.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31/1000, Average Loss: 15.402971363067627\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 32/1000: 100%|███████████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 11.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32/1000, Average Loss: 16.080566310882567\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 33/1000: 100%|███████████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 11.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33/1000, Average Loss: 15.123374748229981\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 34/1000: 100%|███████████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 12.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34/1000, Average Loss: 14.804352569580079\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 35/1000: 100%|███████████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 12.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35/1000, Average Loss: 15.503098964691162\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 36/1000: 100%|███████████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 11.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36/1000, Average Loss: 15.005583190917969\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 37/1000: 100%|███████████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 12.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37/1000, Average Loss: 14.826036930084229\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 38/1000: 100%|███████████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 12.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38/1000, Average Loss: 14.723947334289551\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 39/1000: 100%|███████████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 11.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39/1000, Average Loss: 14.885719108581544\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 40/1000: 100%|███████████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 11.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40/1000, Average Loss: 14.70321798324585\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 41/1000: 100%|███████████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 11.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41/1000, Average Loss: 14.589662837982178\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 42/1000: 100%|███████████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 11.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42/1000, Average Loss: 14.648495960235596\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 43/1000: 100%|███████████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 11.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43/1000, Average Loss: 14.021674823760986\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 44/1000: 100%|███████████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 11.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44/1000, Average Loss: 14.15049877166748\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 45/1000: 100%|███████████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 12.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45/1000, Average Loss: 14.204168510437011\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 46/1000: 100%|███████████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 12.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46/1000, Average Loss: 14.669258880615235\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 47/1000: 100%|███████████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 12.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47/1000, Average Loss: 14.004556941986085\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 48/1000: 100%|███████████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 12.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48/1000, Average Loss: 14.63117847442627\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 49/1000: 100%|███████████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 12.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49/1000, Average Loss: 13.864865684509278\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 50/1000: 100%|███████████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 12.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/1000, Average Loss: 14.139331912994384\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 51/1000: 100%|███████████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 12.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 51/1000, Average Loss: 14.760372829437255\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 52/1000: 100%|███████████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 12.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 52/1000, Average Loss: 14.224181938171387\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 53/1000: 100%|███████████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 12.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 53/1000, Average Loss: 14.192574310302735\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 54/1000: 100%|███████████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 12.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 54/1000, Average Loss: 14.397357940673828\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 55/1000: 100%|███████████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 12.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 55/1000, Average Loss: 14.971416091918945\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 56/1000: 100%|███████████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 12.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56/1000, Average Loss: 14.55145616531372\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 57/1000: 100%|███████████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 12.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 57/1000, Average Loss: 14.3023250579834\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 58/1000: 100%|███████████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 12.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 58/1000, Average Loss: 14.084674835205078\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 59/1000: 100%|███████████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 11.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/1000, Average Loss: 14.213243675231933\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 60/1000: 100%|███████████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 12.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 60/1000, Average Loss: 13.938696002960205\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 61/1000: 100%|███████████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 12.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 61/1000, Average Loss: 13.774949741363525\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 62/1000: 100%|███████████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 12.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 62/1000, Average Loss: 13.864610481262208\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 63/1000: 100%|███████████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 12.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 63/1000, Average Loss: 14.622556781768798\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 64/1000: 100%|███████████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 12.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 64/1000, Average Loss: 14.102963066101074\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 65/1000:  80%|██████████████████████████████████████████████████████▍             | 8/10 [00:00<00:00, 10.94it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[29], line 18\u001b[0m\n\u001b[0;32m     15\u001b[0m     loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m     16\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m---> 18\u001b[0m     total_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n\u001b[0;32m     20\u001b[0m average_loss \u001b[38;5;241m=\u001b[39m total_loss \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mlen\u001b[39m(dataset_train)\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_epochs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Average Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00maverage_loss\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "optimizer = optim.Adam(list(resnet_eeg.parameters()) + list(resnet_mel.parameters()), lr=0.001)\n",
    "batch_size = 2\n",
    "num_epochs = 1000\n",
    "for epoch in range(num_epochs):\n",
    "    total_loss = 0.0\n",
    "    for eeg_input, mel_input in tqdm(dataset_train, desc=f'Epoch {epoch+1}/{num_epochs}'):\n",
    "        optimizer.zero_grad()\n",
    "        # print(eeg_input.shape)\n",
    "        eeg_input, mel_input = eeg_input.view(64,64,320,1).to(device) , mel_input.view(64,10,320,1).to(device)\n",
    "        output_eeg = resnet_eeg(eeg_input)\n",
    "        output_mel = resnet_mel(mel_input)\n",
    "\n",
    "        loss = torch.abs(output_eeg - output_mel).sum()\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    average_loss = total_loss / len(dataset_train)\n",
    "    print(f'Epoch {epoch+1}/{num_epochs}, Average Loss: {average_loss}')\n",
    "\n",
    "# Save the trained models if needed\n",
    "torch.save(resnet_eeg.state_dict(), 'resnet_eeg.pth')\n",
    "torch.save(resnet_mel.state_dict(), 'resnet_mel.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "7f827010-17ff-4cf1-91c4-48cb5f1769aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models as models\n",
    "from tqdm import tqdm  \n",
    "\n",
    "class CustomResNet(nn.Module):\n",
    "    def __init__(self, input_channels):\n",
    "        super(CustomResNet, self).__init__()\n",
    "        self.resnet = models.resnet34(pretrained=False)\n",
    "        self.resnet.conv1 = nn.Conv2d(input_channels, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "        self.resnet.fc = nn.Linear(512, 10)\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.resnet(x)\n",
    "        x = self.softmax(x)\n",
    "        return x\n",
    "\n",
    "resnet_eeg_soft = CustomResNet(64)\n",
    "resnet_mel_soft = CustomResNet(10)\n",
    "\n",
    "resnet_eeg_soft = resnet_eeg_soft.to(device)\n",
    "resnet_mel_soft = resnet_mel_soft.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "eb32925a-84d8-4ddb-a854-fbcd73abbce6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/100: 100%|█████████████████████████████████████████████████████████████████████| 10/10 [00:01<00:00,  9.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100, Average Loss: 0.015461856918409466\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/100: 100%|█████████████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 12.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/100, Average Loss: 0.004576381435617805\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/100: 100%|█████████████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 12.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/100, Average Loss: 0.0028771087527275085\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/100: 100%|█████████████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 12.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/100, Average Loss: 0.004344566829968244\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/100: 100%|█████████████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 12.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/100, Average Loss: 0.0016875833563972265\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/100: 100%|█████████████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 12.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/100, Average Loss: 0.0009590864123310894\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/100: 100%|█████████████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 12.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/100, Average Loss: 0.001036837650462985\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/100: 100%|█████████████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 12.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/100, Average Loss: 0.0014278298651333899\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/100: 100%|█████████████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 12.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/100, Average Loss: 0.0017566319729667157\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/100: 100%|████████████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 12.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/100, Average Loss: 0.001698092941660434\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/100: 100%|████████████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 11.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/100, Average Loss: 0.0015997749462258071\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/100: 100%|████████████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 12.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/100, Average Loss: 0.0021095211151987312\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13/100: 100%|████████████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 11.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/100, Average Loss: 0.0031775612442288548\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14/100:  90%|██████████████████████████████████████████████████████████████       | 9/10 [00:00<00:00, 12.01it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[50], line 20\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m# loss = torch.abs(output_eeg - output_mel).sum()\u001b[39;00m\n\u001b[0;32m     18\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(output_eeg,output_mel)\n\u001b[1;32m---> 20\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     21\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m     23\u001b[0m total_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\torch\\lib\\site-packages\\torch\\_tensor.py:487\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    477\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    478\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    479\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[0;32m    480\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    485\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[0;32m    486\u001b[0m     )\n\u001b[1;32m--> 487\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    488\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[0;32m    489\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\torch\\lib\\site-packages\\torch\\autograd\\__init__.py:200\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    195\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[0;32m    197\u001b[0m \u001b[38;5;66;03m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[0;32m    198\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[0;32m    199\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[1;32m--> 200\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[0;32m    201\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    202\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "optimizer = optim.Adam(list(resnet_eeg_soft.parameters()) + list(resnet_mel_soft.parameters()), lr=0.001)\n",
    "\n",
    "batch_size = 8\n",
    "num_epochs = 100\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    total_loss = 0.0\n",
    "    for eeg_input, mel_input in tqdm(dataset_train, desc=f'Epoch {epoch+1}/{num_epochs}'):\n",
    "        eeg_input, mel_input = eeg_input.view(64,64,320,1).to(device) , mel_input.view(64,10,320,1).to(device)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        output_eeg = resnet_eeg_soft(eeg_input)\n",
    "        output_mel = resnet_mel_soft(mel_input)\n",
    "\n",
    "        # loss = torch.abs(output_eeg - output_mel).sum()\n",
    "        loss = criterion(output_eeg,output_mel)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    average_loss = total_loss / len(dataset_train)\n",
    "    print(f'Epoch {epoch+1}/{num_epochs}, Average Loss: {average_loss}')\n",
    "\n",
    "torch.save(resnet_eeg.state_dict(), 'resnet_eeg_soft.pth')\n",
    "torch.save(resnet_mel.state_dict(), 'resnet_mel_soft.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c55a7b56-5d86-428b-94e1-2e085eea252c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3a57e81-6f97-4f01-910b-52080fbc0004",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89040b2e-2858-4884-8d83-875b78ef9aee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5ef4d66-dba1-45e5-bce5-c22ee37f9999",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbbc4bf6-5f2b-4968-b5bb-218ba34949fb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7 (pytorch)",
   "language": "python",
   "name": "torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
