{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "34a72307",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import glob\n",
    "import json\n",
    "import logging\n",
    "import sys\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import random\n",
    "def batch_equalizer_fn(args):\n",
    "    eeg = args[0]\n",
    "#     print(\"eegshape=\",eeg.shape)\n",
    "    num_stimuli = len(args) - 1\n",
    "    # repeat eeg num_stimuli times\n",
    "    new_eeg = torch.cat([eeg] * num_stimuli, dim=0)\n",
    "    all_features = [new_eeg]\n",
    "#     print(\"all_features=\",all_features[0].shape)\n",
    "\n",
    "    # create args\n",
    "    args_to_zip = [args[i::num_stimuli] for i in range(1, num_stimuli + 1)]\n",
    "#     print(\"args_to_zip=\",args_to_zip[0].shape,args_to_zip[1].shape)\n",
    "\n",
    "    for stimuli_features in zip(*args_to_zip):\n",
    "#         print(\"stimuli_features=\",stimuli_features[0].shape,stimuli_features[1].shape)\n",
    "        for i in range(num_stimuli):\n",
    "            shift = i\n",
    "            shifted_tuple = tuple((stimuli_features[(j - shift) % len(stimuli_features)][0],stimuli_features[(j - shift) % len(stimuli_features)][1]) for j in range(len(stimuli_features)))\n",
    "            stimulus_rolled = torch.stack(tuple(shifted_tuple[i][0] for i in range(len(shifted_tuple))))\n",
    "            mel_rolled = torch.stack(tuple(shifted_tuple[i][1] for i in range(len(shifted_tuple))))\n",
    "#             print(\"stimulus_rolled=\", stimulus_rolled.shape)\n",
    "            # reshape stimulus_rolled to merge the first two dimensions\n",
    "            stimulus_rolled = stimulus_rolled.view(-1, stimulus_rolled.size(2), stimulus_rolled.size(3))\n",
    "            mel_rolled = mel_rolled.view(-1, mel_rolled.size(2), mel_rolled.size(3))\n",
    "#             print(\"stimulus_rolled1=\", stimulus_rolled.shape)\n",
    "\n",
    "            all_features.append((stimulus_rolled,mel_rolled))\n",
    "#     print(\"all_features1=\",all_features)\n",
    "    \n",
    "    labels_list = [torch.tensor([[1 if ii == i else 0 for ii in range(num_stimuli)]]) for i in range(num_stimuli)]\n",
    "    labels = torch.cat([label.repeat(eeg.size(0), 1) for label in labels_list], dim=0)\n",
    "#     print(\"labels=\",labels)\n",
    "#     print(\"tuple(all_features)=\", tuple(all_features))\n",
    "\n",
    "    return tuple(all_features), labels\n",
    "\n",
    "def shuffle_fn(args, number_mismatch):\n",
    "    # repeat the last argument number_mismatch times\n",
    "    args = list(args)\n",
    "    for _ in range(number_mismatch):\n",
    "        args.append((args[-1][0][torch.randperm(args[-1][0].size(0))],args[-1][1][torch.randperm(args[-1][1].size(0))]))\n",
    "    return tuple(args)\n",
    "\n",
    "# Function to create frames from a tensor\n",
    "def frame_tensor(tensor, window_length, hop_length):\n",
    "    num_frames = (tensor.size(0) - window_length) // hop_length + 1\n",
    "    frames = torch.stack(\n",
    "        [tensor[i * hop_length : i * hop_length + window_length] for i in range(num_frames)]\n",
    "    )\n",
    "    return frames\n",
    "\n",
    "def process_eeg(original_tensors_list):\n",
    "    reshaped_tensors = [tensor[i].view(320, 64) for tensor in original_tensors_list for i in range(tensor.size(0))]\n",
    "\n",
    "    lists_of_tensors = [reshaped_tensors[i:i+8] for i in range(0, len(reshaped_tensors), 8)]\n",
    "    lists_of_tensors = lists_of_tensors[:len(reshaped_tensors)//8]\n",
    "\n",
    "    # Shuffle the lists\n",
    "    random.shuffle(lists_of_tensors)\n",
    "\n",
    "    final_tensors = []\n",
    "    for chunk_of_lists in zip(*(iter(lists_of_tensors),) * 8):\n",
    "        concatenated_tensors = torch.cat([torch.unsqueeze(tensor, 0) for sublist in chunk_of_lists for tensor in sublist], dim=0).view(64, 320, 64)\n",
    "        final_tensors.append(concatenated_tensors)\n",
    "\n",
    "    return final_tensors\n",
    "def process_stimuli(original_tensors_list):\n",
    "    reshaped_tensors = [tensor[i].view(320, 1) for tensor in original_tensors_list for i in range(tensor.size(0))]\n",
    "\n",
    "    lists_of_tensors = [reshaped_tensors[i:i+8] for i in range(0, len(reshaped_tensors), 8)]\n",
    "    lists_of_tensors = lists_of_tensors[:len(reshaped_tensors)//8]\n",
    "\n",
    "    # Shuffle the lists\n",
    "    random.shuffle(lists_of_tensors)\n",
    "\n",
    "    final_tensors = []\n",
    "    for chunk_of_lists in zip(*(iter(lists_of_tensors),) * 8):\n",
    "        concatenated_tensors = torch.cat([torch.unsqueeze(tensor, 0) for sublist in chunk_of_lists for tensor in sublist], dim=0).view(64, 320, 1)\n",
    "        final_tensors.append(concatenated_tensors)\n",
    "\n",
    "    return final_tensors\n",
    "\n",
    "def process_mel(original_tensors_list):\n",
    "    reshaped_tensors = [tensor[i].view(320, 10) for tensor in original_tensors_list for i in range(tensor.size(0))]\n",
    "\n",
    "    lists_of_tensors = [reshaped_tensors[i:i+8] for i in range(0, len(reshaped_tensors), 8)]\n",
    "    lists_of_tensors = lists_of_tensors[:len(reshaped_tensors)//8]\n",
    "\n",
    "    # Shuffle the lists\n",
    "    random.shuffle(lists_of_tensors)\n",
    "\n",
    "    final_tensors = []\n",
    "    for chunk_of_lists in zip(*(iter(lists_of_tensors),) * 8):\n",
    "        concatenated_tensors = torch.cat([torch.unsqueeze(tensor, 0) for sublist in chunk_of_lists for tensor in sublist], dim=0).view(64, 320, 10)\n",
    "        final_tensors.append(concatenated_tensors)\n",
    "\n",
    "    return final_tensors\n",
    "class PyTorchDataGenerator(Dataset):\n",
    "    def __init__(self, files, window_length):\n",
    "        self.window_length = window_length\n",
    "        self.files = self.group_recordings(files)\n",
    "\n",
    "    def group_recordings(self, files):\n",
    "        new_files = []\n",
    "        grouped = itertools.groupby(\n",
    "            sorted(files), lambda x: \"_-_\".join(os.path.basename(x).split(\"_-_\")[:3])\n",
    "        )\n",
    "        for recording_name, feature_paths in grouped:\n",
    "            new_files += [sorted(feature_paths, key=lambda x: \"0\" if x == \"eeg\" else x)]\n",
    "#         print(\"new_files=\", new_files[0:4])\n",
    "        return new_files\n",
    "    \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.files)\n",
    "\n",
    "    def __getitem__(self, recording_index):\n",
    "        data = []\n",
    "        for feature in self.files[recording_index]:\n",
    "            f = np.load(feature).astype(np.float32)\n",
    "            if f.ndim == 1:\n",
    "                f = f[:, None]\n",
    "#                 print(\"f_after=\", f.shape)\n",
    "            data += [f]\n",
    "#         print(\"data_before=\", data)\n",
    "        data = self.prepare_data(data)\n",
    "#         print(tuple(torch.tensor(x) for x in data))\n",
    "#         print(\"data_after=\", data)\n",
    "#         print(\"tuple(torch.tensor(x) for x in data)=\",tuple(torch.tensor(x) for x in data))\n",
    "        return tuple(torch.tensor(x) for x in data)\n",
    "\n",
    "    def __call__(self):\n",
    "        for idx in range(self.__len__()):\n",
    "            yield self.__getitem__(idx)\n",
    "\n",
    "            if idx == self.__len__() - 1:\n",
    "                self.on_epoch_end()\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        np.random.shuffle(self.files)\n",
    "\n",
    "    def prepare_data(self, data):\n",
    "        # make sure data has dimensionality of (n_samples, n_features)\n",
    "        return data\n",
    "\n",
    "def create_pytorch_dataset(\n",
    "    data_generator,\n",
    "    window_length,\n",
    "    batch_equalizer_fn=None,\n",
    "    frame_tensor=None,\n",
    "    process_eeg=None,\n",
    "    process_stimuli=None,\n",
    "    process_mel=None,\n",
    "    hop_length=64,\n",
    "    batch_size=64,\n",
    "    number_mismatch=None,\n",
    "    data_types=(torch.float32, torch.float32),\n",
    "    feature_dims=(64, 1)\n",
    "):\n",
    "    dataset = data_generator\n",
    "    if frame_tensor is not None:\n",
    "        dataset = [(frame_tensor(data[0], window_length, hop_length),(frame_tensor(data[1], window_length, hop_length),frame_tensor(data[2], window_length, hop_length))) for data in dataset]\n",
    "\n",
    "\n",
    "    if number_mismatch is not None:\n",
    "        # map second argument to shifted version\n",
    "        dataset = [\n",
    "        shuffle_fn(data, number_mismatch) for data in dataset\n",
    "    ]\n",
    "    \n",
    "    if process_eeg is not None and process_stimuli is not None and process_mel is not None:\n",
    "        # map second argument to shifted version\n",
    "        dataset=[process_eeg([data[0] for data in dataset]),\n",
    "        process_stimuli([data[1][0] for data in dataset]),\n",
    "        process_stimuli([data[2][0] for data in dataset]),\n",
    "        process_stimuli([data[3][0] for data in dataset]),\n",
    "        process_stimuli([data[4][0] for data in dataset]),\n",
    "        process_stimuli([data[5][0] for data in dataset]),\n",
    "        process_mel([data[1][1] for data in dataset]),\n",
    "        process_mel([data[2][1] for data in dataset]),\n",
    "        process_mel([data[3][1] for data in dataset]),\n",
    "        process_mel([data[4][1] for data in dataset]),\n",
    "        process_mel([data[5][1] for data in dataset])]\n",
    "        dataset = [tuple([dataset[0][i],(dataset[1][i],dataset[6][i]),(dataset[2][i],dataset[7][i]),(dataset[3][i],dataset[8][i]),(dataset[4][i],dataset[9][i]),(dataset[5][i],dataset[10][i])]) for i in range(len(dataset[0]))]\n",
    "#         print(dataset[0][0].shape,dataset[0][1].shape,dataset[0][2].shape)\n",
    "\n",
    "    if batch_equalizer_fn is not None:\n",
    "        # Create the labels and make sure classes are balanced\n",
    "        dataset = [\n",
    "            tuple(batch_equalizer_fn(args)) for args in dataset\n",
    "        ]\n",
    "\n",
    "    return tuple(dataset)\n",
    "\n",
    "window_length_s = 5\n",
    "fs = 64\n",
    "\n",
    "window_length = window_length_s * fs  # 5 seconds\n",
    "# Hop length between two consecutive decision windows\n",
    "hop_length = 64\n",
    "\n",
    "epochs = 100\n",
    "patience = 5\n",
    "batch_size = 64 #fixed in the code\n",
    "only_evaluate = True\n",
    "number_mismatch = 4 # or 4\n",
    "\n",
    "\n",
    "\n",
    "training_log_filename = \"training_log_{}_{}.csv\".format(number_mismatch, window_length_s)\n",
    "data_folder = \"split_data/split_data\"\n",
    "\n",
    "# stimulus feature which will be used for training the model. Can be either 'envelope' ( dimension 1) or 'mel' (dimension 28)\n",
    "stimulus_features = [\"envelope\",\"mel\"]\n",
    "stimulus_dimension = 1\n",
    "\n",
    "# uncomment if you want to train with the mel spectrogram stimulus representation\n",
    "# stimulus_features = [\"mel\"]\n",
    "# stimulus_dimension = 10\n",
    "\n",
    "features = [\"eeg\"] + stimulus_features\n",
    "# print(\"features=\", features)\n",
    "train_files = [x for x in glob.glob(os.path.join(data_folder, \"train_-_*\")) if os.path.basename(x).split(\"_-_\")[-1].split(\".\")[0] in features]\n",
    "# Create list of numpy array files\n",
    "train_generator = PyTorchDataGenerator(train_files, window_length)\n",
    "import pdb\n",
    "dataset_train = create_pytorch_dataset(train_generator, window_length, batch_equalizer_fn,frame_tensor,process_eeg,process_stimuli,process_mel,\n",
    "                                  hop_length, batch_size,\n",
    "           \n",
    "                                       number_mismatch=number_mismatch,\n",
    "                                  data_types=(torch.float32, torch.float32),\n",
    "                                  feature_dims=(64, stimulus_dimension))\n",
    "\n",
    "val_files = [x for x in glob.glob(os.path.join(data_folder, \"val_-_*\")) if os.path.basename(x).split(\"_-_\")[-1].split(\".\")[0] in features]\n",
    "val_generator = PyTorchDataGenerator(val_files, window_length)\n",
    "dataset_val = create_pytorch_dataset(val_generator,  window_length, batch_equalizer_fn,frame_tensor,process_eeg,process_stimuli,process_mel,\n",
    "                                  hop_length, batch_size,\n",
    "                                  number_mismatch=number_mismatch,\n",
    "                                  data_types=(torch.float32, torch.float32),\n",
    "                                  feature_dims=(64, stimulus_dimension))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "46d5c587",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([320, 320, 64]) torch.Size([320, 320, 1]) torch.Size([320, 320, 10]) torch.Size([320, 5])\n",
      "torch.Size([320, 320, 64]) torch.Size([320, 320, 1]) torch.Size([320, 320, 10]) torch.Size([320, 5])\n"
     ]
    }
   ],
   "source": [
    "i=0\n",
    "for batch in dataset_train:\n",
    "    print(batch[0][0].shape,batch[0][1][0].shape,batch[0][1][1].shape,batch[1].shape)\n",
    "    i+=1\n",
    "    if i == 2:\n",
    "        break;"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
